import{_ as n}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as s,a,f as i,g as t,o as l}from"./app-BjLrXQO-.js";const r="/assets/concurrent-smp-CBKlATyz.png",d="/assets/concurrent-numa-DOPfwcf4.png",p="/assets/invalidateQueue-CK1tDIPB.png",c={};function o(u,e){return l(),s("div",null,[e[0]||(e[0]=a("h1",{id:"java多线程总结-一-系统理论基础",tabindex:"-1"},[a("a",{class:"header-anchor",href:"#java多线程总结-一-系统理论基础"},[a("span",null,"Java多线程总结（一）：系统理论基础")])],-1)),i(" more "),e[1]||(e[1]=t('<h2 id="一、java多线程发展历史" tabindex="-1"><a class="header-anchor" href="#一、java多线程发展历史"><span>一、Java多线程发展历史</span></a></h2><p>Java多线程的发展可以简单从几个较为关键的点来介绍：<br> ● Java1.5之前：<br> ○ 提供基础的多线程支持，包括Thread和Runnable接口<br> ○ 提供最初的synchronized配合wait()、notify()、notifyAll()的线程同步机制<br> ● Java1.5：<br> ○ 引入了J.U.C，并配套有了大量的并发工具，<br> ○ 引入了Future和Callable，处理异步返回值的问题<br> ○ 完善volatile语义<br> ● Java1.6：synchronized体系知耻而后勇，迎来传说中的“锁升级”<br> ● Java1.7：引入Fork/Join框架<br> ● Java1.8：CompletableFuture携流式API登场，提供的更为丰富的异步编程处理模型<br> ● Java1.9及之后：值得一提的就是Java19的虚拟线程</p><h2 id="二、缓存一致性" tabindex="-1"><a class="header-anchor" href="#二、缓存一致性"><span>二、缓存一致性</span></a></h2><h3 id="_2-1-两种cpu架构" tabindex="-1"><a class="header-anchor" href="#_2-1-两种cpu架构"><span>2.1 两种CPU架构</span></a></h3><p>SMP<br><img src="'+r+'" alt="SMP" loading="lazy"><br> SMP(symmetrical multi-processing, 对称多处理器技术)，在一个计算机上集成多个CPU，各个CPU之间共享内存子系统及总线系统。在任务调度时，系统将任务对称地分布在多个CPU上，所有处理器平等访问内存、IO和外部中断，提高了系统的批处理能力，但同时因为内存共享也带来了高速缓存一致性的问题。缓存一致性的问题通常需要硬件支持，会有硬件性能损耗，并且随着CPU数量的增加而增加，比如一个96核的服务器，每个CPU运行一个线程，每个线程访问同一个变量V，当其中一个线程对V做出修改时，会把消息广播到其余的CPU上，这会造成极大的硬件性能损耗，所以SMP技术很难组件大规模的CPU系统。</p><p>NUMA<br><img src="'+d+`" alt="NUMA" loading="lazy"></p><p>SMP在扩展能力上有一定限制，针对这一问题的探索成果之一就是NUMA（non-uniform memory access，非一致性内存访问）。<br> 在NUMA架构中，一台服务器有多个节点，每个节点有多个CPU，每个节点有自己的内存，节点可以访问自己的内存（近端内存）和其余节点的内存（远端内存）。CPU和近端内存之间通过片内总线连接，节点之间通过互联模块通信。在NUMA架构中，远端内存的访问速度通常为近端内存的20%-77%</p><p>还有诸多其余的CPU架构，不再列举。<br> SMP优势是访问内存速度快，但是扩展性不足，NUMA则与之相反，远端内存的访问速度较低，但是扩展性优秀。<br> 目前，应用服务器大都基于SMP架构设计的，而大规模的数据存储服务器则是基于NUMA架构设计的。在这里我们主要基于SMP架构</p><h3 id="_2-2-mesi协议" tabindex="-1"><a class="header-anchor" href="#_2-2-mesi协议"><span>2.2 MESI协议</span></a></h3><p>目前来讲，大多数CPU都配备不同层级的缓存(L1-L4等)，越高级的缓存性能越强，且更趋向于CPU独享，不难理解缓存一致性问题出现的原因。为解决这一问题，有了各种缓存一致性协议。不同CPU类型支持的缓存一致性协议是不同的，比如有MSI、MESI、MOSI、MESIF等，其中最常用的是MESI协议及其扩展</p><p>缓存一致性协议大致可分为两种策略：<br> ● 写失效：<br> ○ 当一个处理器写入数据时，它会发送一个失效信号到其他处理器，使得其他处理器的缓存中相应的数据副本被标记为无效。<br> ○ 这种方法可以减少总线上的流量，因为只有在数据被写入时才需要通信。<br> ○ 但是，如果有多个处理器频繁读写同一数据，可能会导致较高的失效和缓存一致性维护开销。<br> ● 写更新：<br> ○ 当一个处理器写入数据时，它会发送更新的数据值到所有其他处理器，使得它们的缓存副本也被更新。<br> ○ 这种方法可以减少因数据失效导致的缓存未命中率，特别是在多个处理器共享读取同一数据的情况下。<br> ○ 然而，这可能导致总线上的流量增加，因为每次写操作都需要通知其他所有处理器。</p><p>写失效在一致性协议中更为常见，接下来我们要讨论的MESI就是一种写失效协议</p><p>MESI分别代表了四种数据状态：<br> ● M（Modify）：表示数据只存在于当前缓存，并且已经被修改，与主存内数据不一致<br> ● E（Exclusive）：表示数据只存在于当前缓存，并且没有被修改<br> ● S（Shared）：表示数据存在于多个缓存，数据与主存保持一致<br> ● I（Invalid）：表示数据失效</p><p>四种状态会基于CPU对数据的操作而发生变更，为了维护状态的准确性，所以有了一些必要的监听机制，如<br> ● 如果一个缓存行处于M状态，则它必须监听所有试图获取该缓存行对应的主存地址的操作，并且在操作执行前将缓存数据写回主存<br> ● 如果一个缓存行处于E状态，则它必须监听所有试图获取该缓存行对应的主存地址的操作，一旦有这种操作，需要将当前缓存行的状态设置为S<br> ● 如果一个缓存行处于S状态，则它需要监听其余的“对该缓存行设置Invalid”和“对该缓存行设置Exclusive的操作”，一旦有这种操作，需要将该缓存行状态设置为Invalid<br> ● 等等等等</p><h4 id="_2-2-1-嗅探协议" tabindex="-1"><a class="header-anchor" href="#_2-2-1-嗅探协议"><span>2.2.1 嗅探协议</span></a></h4><blockquote><p>嗅探协议是一种用于维护多处理器系统中缓存一致性的协议。这种协议在基于共享总线的系统中非常有效，因为每个处理器的缓存都可以监听（&quot;嗅探&quot;）总线上的流量来检测其他缓存所做的读写操作。</p></blockquote><p>在使用 Snoopy 协议的系统中，当一个处理器执行读或写操作时，该操作会在总线上广播。其他处理器的缓存控制器会“嗅探”这些操作，并根据它们对共享数据的操作来更新自己的缓存状态。例如，如果一个处理器写入了一个共享变量，其他处理器的缓存中相应的缓存行可能会被标记为无效（invalid），以确保缓存一致性。</p><p>Snoopy 协议通常与缓存一致性协议（如 MESI 协议）结合使用,过程中涉及到的一些消息类型和对应的描述如下：</p><table><thead><tr><th>消息名</th><th>消息类型</th><th>描述</th></tr></thead><tbody><tr><td>Read</td><td>请求</td><td>该消息包含要读取的Cache Line的物理地址，即告知其余处理器，当前处理器准备读取数据</td></tr><tr><td>Read Response</td><td>响应</td><td>该消息包含Read请求中想要读取的数据，该消息可能来自于主存，可能来自于其余处理器，取决于当前缓存行的状态</td></tr><tr><td>Invalidate</td><td>请求</td><td>通知其余处理器将对应缓存行数据设置invalid状态，即失效缓存</td></tr><tr><td>Invalidate Acknowledge</td><td>响应</td><td>当CPU收到invalidate消息时，需要回复该指令，表示自己的缓存行数据已经失效</td></tr><tr><td>Read Invalidate</td><td>请求</td><td>该消息是一个复合操作，告知其余处理机，当前处理机将读取一个数据，并且进行修改操作，希望其余处理器失效对应的缓存行数据。发送该消息的处理器期望收到一个Read Response和多个Invalidate Acknowledge</td></tr><tr><td>Writeback</td><td>请求</td><td>该消息包含需要写回主存的数据及对应的主存</td></tr><tr><td>...</td><td></td><td></td></tr></tbody></table><h4 id="_2-2-2-store-buffer与invalidate-queue" tabindex="-1"><a class="header-anchor" href="#_2-2-2-store-buffer与invalidate-queue"><span>2.2.2 Store Buffer与Invalidate queue</span></a></h4><p>我们注意到，嗅探协议中很多消息都是需要响应的，于是CPU层面就遇到了和应用层面相类似的场景：同步等待响应的过程阻塞了CPU操作，影响了整体的性能。在解决方法上，CPU层面和业务应用层面也是类似的，即同步改异步，于是就有了 <strong>Store Buffer</strong> ，它相当于一个暂存数据，有了它之后，CPU发出对应的指令后，不再同步等待响应，而是先把数据写入StoreBuffer，之后继续执行后面的指令，之后择机将StoreBuffer的数据刷回缓存行。</p><p>但是显然只有StoreBuffer是不行的，按照上面描述的情况，相当于写操作的时候写入了StoreBuffer，但是数据的时候依然是从缓存行读，那么读就有可能读到脏数据，比如下面这个简单的例子</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span>//初始a = 0，是一个shared状态</span></span>
<span class="line"><span>a = 1;</span></span>
<span class="line"><span>b = a+1;</span></span>
<span class="line"><span>assert(b == 2)</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>正常来讲，代码中的assert一定为true，但是a = 1这个操作会进入StoreBuffer，之后b = a + 1中从缓存行中读到的a是0，这就导致了assert失败。针对这个问题，我们首先想到的会是提高StoreBuffer在读时候的优先级，先读StoreBuffer再读缓存行，CPU也确实采用了这个机制，被称为<strong>Store Forwarding</strong>，可惜的是，即便有了StoreForwarding，多核在运行时依然会有问题，再看下面这个例子</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span>int a = 0, b = 0;</span></span>
<span class="line"><span></span></span>
<span class="line"><span>executeToCPU0(){</span></span>
<span class="line"><span>	a = 1;</span></span>
<span class="line"><span>	b = 1;</span></span>
<span class="line"><span>}</span></span>
<span class="line"><span></span></span>
<span class="line"><span>executeToCPU1(){</span></span>
<span class="line"><span>	while(b == 1){</span></span>
<span class="line"><span>		assert(a == 1)</span></span>
<span class="line"><span>	}</span></span>
<span class="line"><span>}</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>executeToCPU0在CPU0上执行，executeToCPU1在CPU1上执行。正常来讲，b==1后a必然为1，也就是说断言会成功，但是在我们目前描述的这些机制下，断言依然会失败。推演一下步骤：</p><ol><li>CPU0执行a = 1，a不存在于CPU0的缓存中，此时发送一个read invalidate消息，希望得到a的值，并且希望其余CPU对应的a缓存失效</li><li>CPU0执行b = 1，b存在于缓存行中，处于modify或者exclusive状态，于是直接更新缓存行b=1</li><li>CPU1执行while，b不存在于缓存中，于是发送一个read invalidate消息</li><li>CPU0响应CPU1对b的消息，返回b = 1</li><li>CPU1继续执行assert语句，a存在于CPU1的缓存行中且等于0，于是此时断言失败</li><li>CPU1收到CPU0对a的read invalidate消息，此时才返回a=0，并且失效自己的缓存，但是可见性问题已经发生了</li></ol><p>可以发现，上述问题的核心还是可见性问题，a的写操作无法即时同步给其余处理器，导致结果看起来像是执行乱序了，仿佛是按下面的顺序执行的</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span>executeToCPU0(){</span></span>
<span class="line"><span>	b = 1;</span></span>
<span class="line"><span>	a = 1;</span></span>
<span class="line"><span>}</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>至此，我们知道的StoreBuffer在提升性能的同时引入了可见性问题，导致CPU操作的指令重排，这个问题最终CPU层面的解决方案是内存屏障，关于内存屏障我们之后介绍，现在我们先来看下StoreBuffer导致的另一个问题。<br> StoreBuffer本身容量非常小，容易被打满，里面的数据只能是在接到ACK之后才能清除，而接收方处理器因为运行状况等原因，无法对ACK的时间作出保证。针对这个问题，CPU在响应ACK时也增加了一个异步处理，即增加了一个InvalidateQueue，对于invalidate操作，先响应再处理，以确保StoreBuffer中等待ACK的数据不会过多。<br><img src="`+p+`" alt="invalidateQueue" loading="lazy"></p><p>和StoreBuffer类似的是，InvalidateQueue的引入在解决性能问题的同时，也引入了可见性问题，会导致指令重排。依然看这个例子：</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span>int a = 0, b = 0;</span></span>
<span class="line"><span></span></span>
<span class="line"><span>executeToCPU0(){</span></span>
<span class="line"><span>	a = 1;</span></span>
<span class="line"><span>	b = 1;</span></span>
<span class="line"><span>}</span></span>
<span class="line"><span></span></span>
<span class="line"><span>executeToCPU1(){</span></span>
<span class="line"><span>	while(b == 1){</span></span>
<span class="line"><span>		assert(a == 1)</span></span>
<span class="line"><span>	}</span></span>
<span class="line"><span>}</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>和之前执行步骤不同的是，这次对于a的invalidate操作已经被CPU1处理，但是它放在了InvalidateQueue当中并未及时生效，因此导致了断言失败。<br> 我们发现，上面描述的两种问题都是因为StoreBuffer或InvalidateQueue的数据没有及时生效，而CPU针对这些情况并没有再进行一些强制的保障，而是提供了内存屏障，将具体的控制器交给开发者</p><h3 id="_2-3-内存屏障" tabindex="-1"><a class="header-anchor" href="#_2-3-内存屏障"><span>2.3 内存屏障</span></a></h3><p>大多数处理器都会提供一下几种内存屏障，以X86为例：<br> ● 读屏障（lfence, load fence）：将invalidate queue中的指令立即处理，并且强制读取缓存行。执行ifence指令之后的操作不会被排到执行ifence之前。这意味着其余CPU暴露出来的缓存行状态对当前CPU可见。（一定要读最新值）<br> ● 写屏障（sfence, store fence）：将Store buffer中的数据修改刷新到本地缓存中，使得其它CPU能看到这些修改。执行sfence之后操作不会被排到执行sfence之前，这意味着执行sfence之前的操作一定全局可见。（写的最新值一定要让所有人都知道）<br> ● 读写屏障（mfence, memeory fence）：相当于ifence和sfence的混合，保证顺序及可见<br> 此外，Lock指令用来修饰操作符，保证原子性，它具有mfence的效果。也就是说任何一个指令搭配上Lock前缀都有内存屏障的效果。在常见的X86架构下，常常使用Lock加一个空操作来实现内存屏障。</p><div class="hint-container tip"><p class="hint-container-title">提示</p><p>读写屏障的功能可以这么记忆：</p><ul><li>读屏障：我想要的是读到最新的数据，我自己写的我肯定能读到，而我这里和别人的写操作相关的就是invalidateQueue，所有需要刷一把它</li><li>写屏障：我想要的是我写完之后大家都能读到最新的，但我管不了其他人，我只能保证我写完之后你再来问我，我一定给到你最新的。我最新的写操作可能在storeBuffer里面，但是你没法读，所有我刷回内存给你读</li></ul></div><p>不同的操作系统会封装不同的方法来对CPU的内存屏障指令进行调用，比如Linux中基于汇编宏命令构建了三种基础的内存屏障：</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span>// :::&quot;memory&quot; 是 GCC 内联汇编的一种语法，用于告诉编译器这段汇编代码可能会影响内存，</span></span>
<span class="line"><span>// 因此编译器应该假设所有缓存的内存值都是无效的，并在需要时重新加载它们。</span></span>
<span class="line"><span>// 编译器决定具体该怎么做，可能会使用lfence、mfence、sfence</span></span>
<span class="line"><span>#define lfence() __asm__ __volatile__(&quot;mfence&quot; ::: &quot;memory&quot;);</span></span>
<span class="line"><span>#define sfence() __asm__ __volatile__(&quot;sfence&quot; ::: &quot;memory&quot;);</span></span>
<span class="line"><span>#define mfence() __asm__ __volatile__(&quot;mfence&quot; ::: &quot;memory&quot;);</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div>`,38))])}const b=n(c,[["render",o],["__file","java-concurrent-1.html.vue"]]),m=JSON.parse('{"path":"/posts/rd/java/%E5%A4%9A%E7%BA%BF%E7%A8%8B/java-concurrent-1.html","title":"Java多线程总结（一）：系统理论基础","lang":"zh-CN","frontmatter":{"icon":"pen-to-square","date":"2024-12-21T00:00:00.000Z","category":["计算机"],"tag":["Java"],"head":[["meta",{"property":"og:url","content":"https://mister-hope.github.io/posts/rd/java/%E5%A4%9A%E7%BA%BF%E7%A8%8B/java-concurrent-1.html"}],["meta",{"property":"og:site_name","content":"阿成的春天和我的太阳"}],["meta",{"property":"og:title","content":"Java多线程总结（一）：系统理论基础"}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2024-12-22T07:41:10.000Z"}],["meta",{"property":"article:tag","content":"Java"}],["meta",{"property":"article:published_time","content":"2024-12-21T00:00:00.000Z"}],["meta",{"property":"article:modified_time","content":"2024-12-22T07:41:10.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"Java多线程总结（一）：系统理论基础\\",\\"image\\":[\\"\\"],\\"datePublished\\":\\"2024-12-21T00:00:00.000Z\\",\\"dateModified\\":\\"2024-12-22T07:41:10.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"Raymond\\",\\"url\\":\\"https://avatars.githubusercontent.com/theflyingraymond\\"}]}"]]},"headers":[{"level":2,"title":"一、Java多线程发展历史","slug":"一、java多线程发展历史","link":"#一、java多线程发展历史","children":[]},{"level":2,"title":"二、缓存一致性","slug":"二、缓存一致性","link":"#二、缓存一致性","children":[{"level":3,"title":"2.1 两种CPU架构","slug":"_2-1-两种cpu架构","link":"#_2-1-两种cpu架构","children":[]},{"level":3,"title":"2.2 MESI协议","slug":"_2-2-mesi协议","link":"#_2-2-mesi协议","children":[]},{"level":3,"title":"2.3 内存屏障","slug":"_2-3-内存屏障","link":"#_2-3-内存屏障","children":[]}]}],"git":{"createdTime":1734845416000,"updatedTime":1734853270000,"contributors":[{"name":"suncheng11","username":"suncheng11","email":"suncheng11@meituan.com","commits":2,"url":"https://github.com/suncheng11"}]},"readingTime":{"minutes":12.17,"words":3652},"filePathRelative":"posts/rd/java/多线程/java-concurrent-1.md","localizedDate":"2024年12月21日","excerpt":"\\n"}');export{b as comp,m as data};
